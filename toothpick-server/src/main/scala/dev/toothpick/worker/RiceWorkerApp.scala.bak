package dev.toothpick.worker

import akka.grpc.GrpcClientSettings
import akka.stream.scaladsl.Source
import dev.toothpick.proto.dstream.{Result, TpDstreamClient}
import com.typesafe.config.Config
import dev.chopsticks.dstream.{DstreamStateMetricsManager, Dstreams}
import dev.chopsticks.fp.AppLayer.AppEnv
import dev.chopsticks.fp.DiEnv.{DiModule, LiveDiEnv}
import dev.chopsticks.fp.akka_env.AkkaEnv
import dev.chopsticks.fp.iz_logging.IzLogging
import dev.chopsticks.fp.util.TaskUtils
import dev.chopsticks.fp.zio_ext._
import dev.chopsticks.fp.{AkkaDiApp, AppLayer, DiEnv, DiLayers}
import dev.chopsticks.util.config.PureconfigLoader
import eu.timepit.refined.types.net.PortNumber
import eu.timepit.refined.types.numeric.PosInt
import eu.timepit.refined.types.string.NonEmptyString
import io.grpc.StatusRuntimeException
import io.prometheus.client.CollectorRegistry
import pureconfig.ConfigConvert
import zio.{Schedule, Task, UIO, ZIO, ZLayer, ZManaged}

import scala.collection.immutable.ListMap
import scala.concurrent.duration._
import scala.jdk.DurationConverters.ScalaDurationOps

final case class TpWorkerAppConfig(parallelism: PosInt, serverHost: NonEmptyString, serverPort: PortNumber)

object TpWorkerAppConfig {
  //noinspection TypeAnnotation
  implicit lazy val configConvert = {
    import dev.chopsticks.util.config.PureconfigConverters._
    ConfigConvert[TpWorkerAppConfig]
  }
}

object TpWorkerApp extends AkkaDiApp[TpWorkerAppConfig] {

  override def config(allConfig: Config): Task[TpWorkerAppConfig] = {
    Task(PureconfigLoader.unsafeLoad[TpWorkerAppConfig](allConfig, "app"))
  }

  override def liveEnv(
    akkaAppDi: DiModule,
    appConfig: TpWorkerAppConfig,
    allConfig: Config
  ): Task[DiEnv[AppEnv]] = {
    Task {
      val extraLayers = DiLayers(
        ZLayer.succeed(CollectorRegistry.defaultRegistry),
        AppLayer(app)
      )
      LiveDiEnv(extraLayers ++ akkaAppDi)
    }
  }

  //noinspection TypeAnnotation
  def app = {
    for {
      runFib <- run.fork
      periodicLoggingFib <- periodicallyLog.fork
      _ <- TaskUtils.raceFirst(
        List(
          "Run" -> runFib.join,
          "Periodic logging" -> periodicLoggingFib.join
        )
      )
    } yield ()
  }

  private def periodicallyLog = {
    val io = for {
      zlogger <- IzLogging.zioLogger
      dstreamMetrics <- ZIO.accessM[DstreamStateMetricsManager](_.get.activeSet)
      metricsMap <- UIO {
        ListMap(
          "workers" -> dstreamMetrics.iterator.map(_.dstreamWorkers.get).sum.toString,
          "attempts" -> dstreamMetrics.iterator.map(_.dstreamAttemptsTotal.get).sum.toString,
          "queue" -> dstreamMetrics.iterator.map(_.dstreamQueueSize.get).sum.toString,
          "map" -> dstreamMetrics.iterator.map(_.dstreamMapSize.get).sum.toString
        )
      }
      formatted = metricsMap.iterator.map { case (k, v) => s"$k=$v" }.mkString(" ")
      _ <- zlogger.info(s"${formatted -> "formatted" -> null}")
    } yield ()
    io.repeat(Schedule.fixed(1.second.toJava)).unit
  }

  protected def runWorker(client: TpDstreamClient, id: Int) = {
    Dstreams
      .work(client.work().addHeader(Dstreams.WORKER_ID_HEADER, id.toString)) { assignment =>
        UIO {
          Source
            .single(1)
            .map(v => Result(assignment.valueIn * 10 + v))
        }
      }
  }

  private def run = {
    val managedClient = for {
      appConfig <- ZManaged.access[AppConfig](_.get)
      akkaEnv <- ZManaged.access[AkkaEnv](_.get)
      client <- Dstreams
        .manageClient {
          UIO {
            import akkaEnv.actorSystem

            TpDstreamClient(
              GrpcClientSettings
                .connectToServiceAt("localhost", 9999)
                .withTls(false)
            )
          }
        }
    } yield {
      ZIO.forkAll_ {
        (1 to appConfig.parallelism.value).map { id =>
          runWorker(client, id)
            .foldM(
              {
                case e: StatusRuntimeException => ZIO.fail(e)
                case e => ZIO.left(e)
              },
              r => ZIO.right(r)
            )
            .log(s"Worker $id")
            .repeat(Schedule.forever)
        }
      }
    }

    managedClient.use(identity)
  }
}
